\section{Mem Mgmnt, Paging}
The disk is cheap, but very slow, so the DRAM acts like a cache for the disk. The
OS helps programmers use DRAM through virtual memory. The goals of memory management are
efficiency, transparency, and protection/sharing. For transparency, we give
each process its own view of memory ($0 \rightarrow 2^{64} - 1$). \textit{fixed
partitioning} has unequal sized partitions with a queue for each partition
(process -> smallest fitting queue) (prob: lots of unused space).
\textit{dynamic partitioning} puts a process into a partition of the right size
it needs to hold it (prob: external frag, compaction may require processes to
be \textit{relocatable}). We use \textbf{paging} to manage memory, where we
decouple address space from physical location. A \textbf{page table} is used to
translate virtual to physical addresses, each process has its own. \textbf{page
faults} are handled by the OS, which loads a page from disk, and the process is
paused until the data is brought from memory. Processes reference pages in
\textbf{localized patterns} (temporal, spatial). The VM enforces protection by
keeping address spaces isolated (per-process), and information leaks are
prevented by using a 0-ed out page and giving the VA of that page, also COW. We
also need to have address binding. This can happen either at compile time
(relocation not possible), at load time (relocation not possible; the linker
creates absolute addresses within executable), or dynamically (executables
contain logical, not absolute, addresses which are translated during
execution). H/W supports dynamic relocation with a \textit{base} and
\textit{bound} registers on the MMU. The OS decided where to place address
space in physical memory when the process is run. It first sets the base
register, then the physicall address is: base + virtual address. The bound
register ensures that we dont access things outside the given address space.
(only one base/bound register, gets saved to PCB during context switch so it ca
n be used for $n$ processes). Since proccesses are now relocatable, we use
compaction to ``resolve'' external fragmentation (expensive and not always possible).
given some vaddr, u can find the following with
$ {\tt page} = {\tt vaddr} << b $,
$ {\tt offset} = {\tt vaddr} \& ( (1 << b) - 1)$,
${\tt physaddr} = ({\tt frame} << b) + {\tt offset}$, where frame is from the
value at the index {\tt page} in the page table. 

Memory for linear page tables is large, since 1PTE/page. We can reduce space by
only mapping what is being used, so a page table for code/stack/heap, which
means we need three pairs ofbase/bound registers, but this can cause external
fragrmentation, since page tables can be arbitrary size (finding free space is
difficult). So we use {\it multi level page tables}, which split a page table
into pages of PTE (page table entries), and use a page table directory to point
diff pages of PTE. {\tt Two level page tables }: virtual addresses (VAs) have 3
parts: (1) page directory (1)master, which maps VA to secondary page table, (2) secondary
page table which maps page num to physical frame, (3) offset selects address
w/in physical frame. 32 bit address space => 4k pages => 4 bytes/pte => 12 bits
offset => 10 bits master, 10 bits secondary. We can also use {\tt hashed page
tables}, which maps virtual page number (vpn) to bucket, and u search entries
in that bucket for vpn. {\tt inverted page tables} keep only one page table for
the whole system, with an entry for each physical page frame (entry has vpn and
pid), but this makes lookup slower.

We use a {\bf TLB} to help with timing limitations, which translates vpns into
PTE.\ these are implemented in the hardware, and they cache \{ vpn: vpe \}. Tlbs
exploit locality, but TLB can still miss (99\% hit rate tho), and managing TLBs
can happen via hardware or software. To {\bf manage page tables}, the OS needs
to make sure that TLB is consistent w/ page table, so updating bit in a PTE =>
updating TLB.\ On a context switch, the TLB needs to be reloaded. If the TLB
misses and new PTE has to be loaded, a cached PTE needs ot be evicted. When a
process accesses a page that has been evicted, (1) the OS sets the PTE as
invalid, stores the locatio of the page in the swap file in PTE.\ (2) when a
proccess accesses that page, PTE causes a trap (page fault), (3) trap will run
OS page fault handler. (4) handler uses invalid PTE to find page in swp file.
(5) reads page into physical frame, updates PTE to point ot it. (6) resume
process. OS usually keeps pool of free pages so we dont always have to evict.
